# fund_scorecard_metrics.py
import io
import re
import tempfile
from pathlib import Path

import pandas as pd
import pdfplumber
import streamlit as st

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. Regex helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TICKER_RE = re.compile(r"(.+?)\s{2,}([A-Z0-9]{1,6}[A-Z]?)\s?[â€ *]?$")
METRIC_RE = re.compile(
    r"^(Manager Tenure|Excess Performance|Peer Return Rank|Expense Ratio Rank|"
    r"Sharpe Ratio Rank|R-Squared|Sortino Ratio Rank|Tracking Error Rank)"
    r"\s+(Pass|Review)"
)

WATCHLIST_POS = re.compile(r"Fund Meets Watchlist Criteria", flags=re.I)
WATCHLIST_NEG = re.compile(r"placed on watchlist", flags=re.I)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. Build master lookup  (Fund âœ Ticker)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_ticker_lookup(pages_text: list[str]) -> dict[str, str]:
    lookup: dict[str, str] = {}
    for page_txt in pages_text:
        for line in page_txt.splitlines():
            m = TICKER_RE.match(line.strip())
            if m:
                lookup[m.group(1).strip()] = m.group(2).strip()
    return lookup


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. Find bestâ€‘matching fund name in a block
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def pick_fund_name(block: str, lookup: dict[str, str]) -> tuple[str, bool]:
    """Return (fund_name, confident?)."""
    block_lower = block.lower()

    # 3â€‘A. Exact substring first
    for name in lookup:
        if name.lower() in block_lower:
            return name, True

    # 3â€‘B. Fuzzy match (RapidFuzz â‰¥85)
    try:
        from rapidfuzz import fuzz, process  # type: ignore
    except ModuleNotFoundError:
        return "UNKNOWN FUND", False

    choice, score, _ = process.extractOne(
        block, lookup.keys(), scorer=fuzz.token_set_ratio  # type: ignore
    )
    return (choice, score >= 85)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. Main Streamlit app
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run():
    st.set_page_config("Fund Scorecard Metrics", layout="wide")
    st.title("Fundâ€¯Scorecardâ€¯Metrics")

    st.markdown(
        "Upload an **MPIâ€‘style PDF** fund scorecard.â€¯The app extracts each fund, "
        "evaluates it against the watchâ€‘list criteria, and shows a breakdown of "
        "metric statuses."
    )

    pdf_bytes = st.file_uploader("ğŸ“„â€¯Upload MPI PDF", type=["pdf"])
    if not pdf_bytes:
        st.info("Waiting for a PDFâ€¦")
        st.stop()

    # Save to a temp file so pdfplumber can memoryâ€‘map large docs safely
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(pdf_bytes.read())
        tmp_path = Path(tmp.name)

    rows: list[dict] = []
    low_confidence: list[dict] = []

    # â”€â”€ Passâ€¯1: read every page txt once â”€â”€
    pages_text: list[str] = []
    with pdfplumber.open(tmp_path) as pdf:
        progress = st.progress(0.0, "ğŸ”â€¯Scanning PDFâ€¦")
        for i, page in enumerate(pdf.pages, start=1):
            pages_text.append(page.extract_text() or "")
            progress.progress(i / len(pdf.pages))
        progress.empty()

    ticker_lookup = build_ticker_lookup(pages_text)

    # â”€â”€ Passâ€¯2: parse criteria blocks â”€â”€
    st.caption("Parsing watchâ€‘list sectionsâ€¦")
    block_splitter = re.compile(
        r"\n(?=[^\n]{0,120}Fund (?:Meets Watchlist Criteria|has been placed on watchlist))",
        flags=re.I,
    )

    for page_txt in pages_text:
        if "Fund Scorecard" not in page_txt:
            continue
        # If horizontal rule markers exist (â€œâ”€â”€â”€â”€â”€â”€â”€â”€â€), split on them too
        sections = re.split(r"(?:â”€{5,})", page_txt)
        for section in sections:
            blocks = block_splitter.split(section)
            for block in blocks:
                if not WATCHLIST_POS.search(block) and not WATCHLIST_NEG.search(block):
                    continue

                name, confident = pick_fund_name(block, ticker_lookup)
                ticker = ticker_lookup.get(name, "N/A")
                meets = "Yes" if WATCHLIST_NEG.search(block) is None else "No"

                metrics = {
                    m.group(1): m.group(2)
                    for m in (METRIC_RE.match(line.strip()) for line in block.splitlines())
                    if m
                }

                record = {
                    "Fund Name": name,
                    "Ticker": ticker,
                    "Meets Criteria": meets,
                    **metrics,
                }

                if confident:
                    rows.append(record)
                else:
                    low_confidence.append(record)

    # â”€â”€ Output results â”€â”€
    if not rows and not low_confidence:
        st.error("âŒâ€¯No fund entries found.â€¯This PDF may use an unsupported template.")
        st.stop()

    df = pd.DataFrame(rows)
    st.success(f"âœ…â€¯Capturedâ€¯{len(df)} fund entries.")
    st.dataframe(df, use_container_width=True)

    if low_confidence:
        st.warning(
            f"âš ï¸â€¯{len(low_confidence)} additional entries had lowâ€‘confidence name matches."
        )
        with st.expander("Show lowâ€‘confidence matches"):
            st.dataframe(pd.DataFrame(low_confidence), use_container_width=True)

    # Downloads
    with st.expander("ğŸ“¥â€¯Download Results"):
        st.download_button(
            "CSV (highâ€‘confidence only)",
            df.to_csv(index=False).encode(),
            file_name="fund_criteria_results.csv",
            mime="text/csv",
        )
        if low_confidence:
            all_df = pd.concat([df, pd.DataFrame(low_confidence)], ignore_index=True)
            st.download_button(
                "CSV (all entries)",
                all_df.to_csv(index=False).encode(),
                file_name="fund_criteria_results_all.csv",
                mime="text/csv",
            )


if __name__ == "__main__":
    run()
